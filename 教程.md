# Memosyne 零基础通关教程

> 本教程面向从未接触过该项目、对 Python 也只停留在“略懂”阶段的绝对初学者。我们会按层次拆解整个仓库，从环境准备、代码结构，到关键模块的逐行讲解与练习，最后带你串联成一个可运行的脚本，并用费曼学习法复盘知识点。

---

## 1. 开始之前：必须具备的前置知识

1. **Python 基础语法**  
   需要知道如何运行 `python` 命令、理解函数、类、模块的概念。推荐先完成一门入门课程（如《Python 100 例》或官方教程前 5 章）。
2. **虚拟环境（virtualenv/venv）**  
   虚拟环境能为不同项目隔离依赖，避免“装了一个包，所有项目都跟着崩”。在命令行中执行：
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # macOS/Linux
   .venv\Scripts\activate    # Windows
   ```
   退出虚拟环境时运行 `deactivate`。
3. **阅读 README.md**  
   仓库根目录的 [README](README.md) 已整理好特性、安装步骤、以及 CLI/API 的使用方法。先通读一遍，了解项目的总体目标和“分层架构”概念，后续章节会频繁引用其中的术语。

---

## 2. 探索仓库布局

进入仓库根目录后，先用 `ls`（Windows 可用 `dir`）观察顶层结构：

```
ARCHITECTURE.md  README.md  requirements.txt  src/  data/  db/
```

- `ARCHITECTURE.md`：深度解构系统架构。
- `data/` 与 `db/`：放置输入输出样例和基础术语表。
- `src/`：项目核心代码所在，按照 README 所述分为 `config → core → models → providers → repositories → services → cli` 七层。

**建议**：边看边画脑图，写下每一层的职责。对照 README 中“专业架构”一节，可以看到同样的分层顺序。【F:README.md†L31-L62】

---

## 3. 配置层：`src/memosyne/config/settings.py`

### 它解决什么问题？

任何真实项目都需要读取 API Key、数据目录等配置。`settings.py` 将这些配置集中管理，并用 [Pydantic](https://docs.pydantic.dev) 提供的 `BaseSettings` 自动读取 `.env` 文件、做类型验证，避免“环境变量拼错导致线上翻车”。

### 关键代码逐行拆解

```python
from pathlib import Path
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    openai_api_key: str
    default_llm_provider: Literal["openai", "anthropic"] = "openai"
    data_dir: Path = Field(default=Path("data"))

    model_config = SettingsConfigDict(env_file=str(_PROJECT_ROOT / ".env"))
```

1. `Path` 让我们使用面向对象的方式处理文件路径。
2. 继承 `BaseSettings` 的 `Settings` 类：定义每个配置项的名称、类型、默认值。
3. `Literal` 保证 `default_llm_provider` 只能在两个选项中取值；如果 `.env` 写了其他字符串会直接报错。
4. `Field(default=Path("data"))` 指定默认目录，同时允许使用者在 `.env` 中覆盖。
5. `model_config` 告诉 Pydantic 去 `.env` 里找真实值，自动处理大小写，并忽略不认识的变量。

### 练习：实现你自己的迷你配置类

**任务**：创建一个最小可用的配置类 `MiniSettings`，只包含 `project_name`（字符串，默认 `"demo"`）和 `debug`（布尔值，默认 `False`）。打印实例以验证默认值。

**示例代码**：
```python
class MiniSettings(BaseSettings):
    project_name: str = "demo"
    debug: bool = False

mini = MiniSettings()
print(mini.project_name, mini.debug)
```
**预期输出**：
```
demo False
```

### 延伸思考
- 为何 `_find_project_root()` 要向上查找 `.env` 或 `data/db` 目录？（提示：方便脚本在任何工作目录下运行。）【F:src/memosyne/config/settings.py†L13-L35】
- `ensure_dirs()` 如何保证输入输出目录存在？【F:src/memosyne/config/settings.py†L88-L112】

---

## 4. 核心接口层：`src/memosyne/core/interfaces.py`

### 它解决什么问题？

为了保持高层代码独立于具体实现，项目使用 Python 的 `Protocol` 和抽象基类（ABC）定义统一接口。这样，服务层只依赖“会 `complete_prompt` 的对象”，而不关心它背后调用的是 OpenAI 还是未来的自研模型。

### 关键代码逐行拆解

```python
@runtime_checkable
class LLMProvider(Protocol):
    def complete_prompt(self, word: str, zh_def: str) -> dict: ...
```

- `Protocol` 允许鸭子类型：任何类只要实现了同名方法，就“自动”符合接口。
- `runtime_checkable` 让我们能在运行时使用 `isinstance(obj, LLMProvider)` 做校验。

```python
class BaseLLMProvider(ABC):
    def __init__(self, model: str, temperature: float | None = None):
        self.model = model
        self.temperature = temperature
        self._validate_config()
```

- `ABC` 强制子类实现抽象方法，并允许共享公共逻辑（如构造器验证）。
- `_validate_config` 在基础类中检查模型 ID 是否为空，子类还能覆盖加更多校验。

### 练习：写一个模拟 Provider

**任务**：实现一个 `DummyProvider`，继承 `BaseLLMProvider`，返回固定的字典：`{"IPA": "/demo/", "POS": "n."}`。

**示例代码**：
```python
class DummyProvider(BaseLLMProvider):
    def complete_prompt(self, word: str, zh_def: str) -> dict:
        return {"IPA": "/demo/", "POS": "n."}

print(DummyProvider(model="fake"))
```
**预期输出**：
```
DummyProvider(model='fake')
```

### 延伸思考
- 为什么还要定义 `CSVRepository` 协议？思考服务层如何在不感知 CSV 细节的情况下读写数据。【F:src/memosyne/core/interfaces.py†L58-L78】

---

## 5. 模型层：`src/memosyne/models/term.py`

### 它解决什么问题？

该文件用 Pydantic 模型统一描述术语在不同阶段（输入、LLM 响应、输出、批次信息）的数据结构。模型负责 **验证**（无效数据直接报错）和 **序列化**（转换为字典、CSV 行）。

### 关键代码逐行拆解

```python
class TermInput(BaseModel):
    word: str = Field(..., min_length=1)
    zh_def: str = Field(..., min_length=1)

    @field_validator("word", "zh_def")
    def strip_whitespace(cls, v: str) -> str:
        stripped = v.strip()
        if not stripped:
            raise ValueError("字段不能为空或仅包含空白")
        return stripped
```

- `Field(..., min_length=1)` 声明字段必填且至少一个字符。
- `field_validator` 自动去除空白并在必要时抛出异常。

```python
class LLMResponse(BaseModel):
    ipa: str = Field(default="", alias="IPA")
    pos: Literal["n.", "vt.", "vi.", "adj.", "adv.", "P.", "O.", "abbr."] = Field(..., alias="POS")
    en_def: str = Field(..., alias="EnDef")
    example: str = Field(..., alias="Example")
```

- `alias` 让模型既能读取 `IPA` 这样的全大写键，也能用 `.ipa` 访问。
- `Literal` 控制取值范围，避免 LLM 输出奇怪的词性字符串。

```python
class TermOutput(BaseModel):
    @classmethod
    def from_input_and_llm(cls, term_input, llm_response, memo_id, tag_cn, batch_id, batch_note=""):
        return cls(
            wm_pair=f"{term_input.word} - {term_input.zh_def}",
            memo_id=memo_id,
            ...
        )
```

- 工厂方法将输入、LLM 响应、批次信息拼装成最终输出，便于服务层直接调用。

### 练习：体验数据验证

**任务**：尝试创建 `TermInput(word="  ", zh_def="神经元")`，观察 Pydantic 抛出的错误信息；然后改成 `TermInput(word="neuron", zh_def=" 神经元 ")`，验证它自动去空白。

**预期现象**：
- 第一次调用会抛出 `ValueError: 字段不能为空或仅包含空白`。
- 第二次返回对象，`zh_def` 的值会是 `"神经元"`（前后空格被剥离）。

### 延伸思考
- 为什么 `LLMResponse` 要用 `model_validator` 把缩写的 IPA 清空？【F:src/memosyne/models/term.py†L89-L104】
- `BatchMetadata` 记录了哪些元数据？它们在导出报表时有什么用？【F:src/memosyne/models/term.py†L160-L167】

---

## 6. Provider 层：`src/memosyne/providers/openai_provider.py`

### 它解决什么问题？

`OpenAIProvider` 负责与 OpenAI Chat Completions API 对话：组装提示词、调用接口、解析 JSON，并将错误包装成项目自定义的 `LLMError`。

### 关键代码逐行拆解

```python
class OpenAIProvider(BaseLLMProvider):
    def __init__(self, model: str, api_key: str, temperature: float | None = None, max_retries: int = 2):
        self.client = OpenAI(api_key=api_key, max_retries=max_retries)
        super().__init__(model=model, temperature=temperature)
```

- 初始化时创建官方 SDK 的 `OpenAI` 客户端，并调用基类构造器做验证。

```python
SYSTEM_PROMPT = """You are a terminologist ..."""
USER_TEMPLATE = """Given:\nWord: {word}\nZhDef: {zh_def}\n..."""
```

- `SYSTEM_PROMPT` 定义角色设定与字段规则。
- `USER_TEMPLATE` 将词条与中文释义塞进提示词，指导模型输出指定键。

```python
response = self.client.chat.completions.create(**kwargs)
content = response.choices[0].message.content
return json.loads(content)
```

- 调用 Chat Completions。
- 从首个候选答案里取出 JSON 字符串，并用 `json.loads` 转成字典供 Pydantic 模型消费。

### 练习：模拟一次调用

**任务**：编写一个 `FakeOpenAIProvider`，继承 `BaseLLMProvider`，`complete_prompt` 返回硬编码 JSON，与真实接口格式一致。

**示例代码**：
```python
class FakeOpenAIProvider(BaseLLMProvider):
    def __init__(self):
        super().__init__(model="mock")

    def complete_prompt(self, word: str, zh_def: str) -> dict:
        return {
            "IPA": "/ˈdemo/",
            "POS": "n.",
            "Rarity": "",
            "EnDef": f"A mock definition for {word}",
            "Example": f"This is a sentence with {word}.",
            "PPfix": "",
            "PPmeans": "",
            "TagEN": "testing"
        }
```
**预期输出**：调用该类的 `complete_prompt` 应返回结构化字典，无需访问真实 OpenAI。

### 延伸思考
- 为什么要捕获 `BadRequestError` 并在温度不被支持时重试？（提示：不同模型可能不允许自定义温度。）【F:src/memosyne/providers/openai_provider.py†L96-L115】

---

## 7. 仓储层：`src/memosyne/repositories/csv_repository.py`

### 它解决什么问题？

术语数据主要存放在 CSV 文件中。`CSVTermRepository` 将“读 CSV”与“写 CSV”的细节封装起来：自动识别分隔符、容错列名、输出固定字段顺序，为服务层提供简洁接口。

### 关键代码逐行拆解

```python
def _pick_first(d: dict[str, str], candidates: Iterable[str]) -> str:
    for k in candidates:
        if k in d and d[k]:
            return d[k]
    return ""
```

- 遍历所有可能的列名（含中英文别名），找到第一个非空值。

```python
with open(path, "r", encoding="utf-8-sig", newline="") as f:
    reader = csv.DictReader(f, dialect=dialect)
    for row in reader:
        clean = {norm_key: (val or "").strip() for ...}
        word = _pick_first(clean, ["word"] + list(_WORD_KEYS))
```

- 用 `csv.Sniffer` 自动识别分隔符（逗号/分号/制表符）。
- 清洗每行数据，再用 `_pick_first` 找到词条和中文释义。

```python
terms.append(TermInput(word=word, zh_def=zh))
```

- 将结果交给 `TermInput`，利用模型自身的验证逻辑过滤无效行。

### 练习：创建迷你 CSV

1. 新建文件 `sample.csv`，写入：
   ```csv
   word,中文释义
   neuron,神经元
   ```
2. 在 Python REPL 中执行：
   ```python
   from memosyne.repositories.csv_repository import CSVTermRepository
   terms = CSVTermRepository.read_input("sample.csv")
   print(terms[0].word, terms[0].zh_def)
   ```
**预期输出**：`neuron 神经元`

### 延伸思考
- 如果输入 CSV 没有任何有效行，会抛出什么错误？阅读文件尾部的 `raise ValueError(...)` 找答案。【F:src/memosyne/repositories/csv_repository.py†L55-L74】

---

## 8. 服务层：`src/memosyne/services/term_processor.py`

### 它解决什么问题？

`TermProcessor` 是 MMS（术语处理）功能的核心 orchestrator：循环遍历输入词条，调用 LLM、应用业务规则、拼装输出，并记录批次信息。

### 关键代码逐行拆解

```python
class TermProcessor:
    def __init__(self, llm_provider, term_list_mapping, start_memo_index, batch_id, batch_note=""):
        self.llm = llm_provider
        self.term_mapping = term_list_mapping
        self.start_memo = start_memo_index
        self.batch_id = batch_id
        self.batch_note = f"「{batch_note.strip()}」" if batch_note else ""
```

- 通过构造函数注入所有依赖，方便测试（可传入假的 Provider、假的映射表）。
- `batch_note` 会自动包裹中文书名号，统一输出格式。

```python
for index, term_input in iterator:
    llm_dict = self.llm.complete_prompt(word=term_input.word, zh_def=term_input.zh_def)
    llm_response = LLMResponse(**llm_dict)
    llm_response = self._apply_business_rules(term_input.word, llm_response)
    tag_cn = self._get_chinese_tag(llm_response.tag_en)
    memo_id = self._generate_memo_id(index)
    output = TermOutput.from_input_and_llm(...)
```

- 处理流程清晰：LLM → 校验 → 业务规则 → 标签映射 → Memo ID → 组装输出。
- `_generate_memo_id` 与 `_get_chinese_tag` 将细节封装成独立方法，便于单元测试。

### 练习：拼接“假数据”管线

**任务**：利用前面实现的 `FakeOpenAIProvider`，构造 `TermProcessor`，传入一个 `TermInput`，观察输出。

```python
from memosyne.models.term import TermInput

fake_terms = [TermInput(word="hippocampus", zh_def="海马体")]
fake_mapping = {"neuroscience": "神经"}
processor = TermProcessor(
    llm_provider=FakeOpenAIProvider(),
    term_list_mapping=fake_mapping,
    start_memo_index=2700,
    batch_id="251101A001"
)
outputs = processor.process(fake_terms, show_progress=False)
print(outputs[0].memo_id, outputs[0].en_def)
```
**预期输出**：类似 `M002701 A mock definition for hippocampus`

### 延伸思考
- `_get_chinese_tag` 里的“宽松包含匹配”如何处理 `neurobiology` 这类词？【F:src/memosyne/services/term_processor.py†L123-L151】
- 如果 LLM 调用失败，为什么要打印错误后 `raise`？思考调用方（CLI）应该如何响应。【F:src/memosyne/services/term_processor.py†L95-L108】

---

## 9. CLI 层：`src/memosyne/cli/mms.py` 与 `src/memosyne/cli/exparser.py`

### 它们解决什么问题？

- `mms.py`：面向术语 CSV 的交互式终端脚本，负责采集用户输入、初始化依赖、调用 `TermProcessor`、输出结果。
- `exparser.py`：面向 Quiz Markdown 的终端脚本，负责读取文本、调用 Quiz Parser 服务、输出 `ShouldBe.txt`。

### `mms.py` 核心流程

```python
settings = get_settings(); settings.ensure_dirs()
model_input = ask("引擎...")
provider_type, model_id, _ = resolve_model_choice(model_input)
input_path, start_memo = resolve_input_and_memo(path_input, settings.mms_input_dir)
llm_provider = OpenAIProvider(...)
terms_input = CSVTermRepository.read_input(input_path)
term_list_repo = TermListRepo(); term_list_repo.load(...)
batch_id = BatchIDGenerator(...).generate(term_count=len(terms_input))
processor = TermProcessor(...)
results = processor.process(terms_input)
CSVTermRepository.write_output(output_path, results)
```

- 借助一系列 `resolve_*` 函数，把用户在 CLI 输入的字符串转换成实际配置。
- CLI 自身不处理任何业务逻辑，只负责“拼装依赖 + 打印友好的提示”。

### `exparser.py` 核心流程

```python
settings = get_settings()
input_path = _resolve_input_md(user_input, settings)
output_path = _resolve_output_path(user_input, settings)
title_main, title_sub = _infer_titles_from_filename(input_path)
md_text = input_path.read_text(encoding="utf-8")
llm = OpenAIProvider(...)
items = QuizParser(llm_provider=llm).parse(md_text)
out_text = QuizFormatter().format(items, title_main, title_sub)
output_path.write_text(out_text, encoding="utf-8")
```

- 相同的套路：读取配置 → 解析路径 → 调用服务 → 写出结果。
- `_infer_titles_from_filename` 展示了如何从文件名中拆出主副标题，是练习字符串处理的好例子。

### CLI 练习

1. 激活虚拟环境并安装依赖：
   ```bash
   pip install -r requirements.txt
   ```
2. 创建 `.env` 并填入真实（或假的）API Key。
3. 运行术语 CLI：
   ```bash
   python src/memosyne/cli/mms.py
   ```
   根据提示输入模型、CSV 路径、Memo 起始编号。若使用假 Provider，可改动脚本在创建 Provider 的部分直接实例化 `FakeOpenAIProvider`。
4. 运行 Quiz CLI：
   ```bash
   python src/memosyne/cli/exparser.py
   ```

**预期输出**：终端显示读取词条、生成 BatchID、写出结果的日志；Quiz CLI 会打印解析到的题目数与输出文件路径。

---

## 10. 端到端串联：从配置到输出

这一节，我们将把所有模块拼成一个最小可运行的脚本，模拟“初学者向朋友讲解”过程（费曼学习法）。

### 步骤 1：准备环境

```bash
python -m venv .venv
source .venv/bin/activate  # 或 .venv\Scripts\activate
pip install -r requirements.txt
```

在根目录创建 `.env`：
```env
OPENAI_API_KEY=sk-proj-demo
DEFAULT_LLM_PROVIDER=openai
```

### 步骤 2：写一个迷你脚本 `demo_pipeline.py`

```python
from memosyne.config import get_settings
from memosyne.models.term import TermInput
from memosyne.providers.openai_provider import OpenAIProvider
from memosyne.repositories.csv_repository import CSVTermRepository
from memosyne.services.term_processor import TermProcessor

settings = get_settings()
settings.ensure_dirs()

fake_terms = [TermInput(word="neuron", zh_def="神经元")]
term_mapping = {"neuroscience": "神经"}

llm = OpenAIProvider(model=settings.default_openai_model, api_key=settings.openai_api_key)
processor = TermProcessor(
    llm_provider=llm,
    term_list_mapping=term_mapping,
    start_memo_index=2700,
    batch_id="251101A001",
)

results = processor.process(fake_terms, show_progress=False)
CSVTermRepository.write_output("demo_output.csv", results)
print("✅ Pipeline done! -> demo_output.csv")
```

### 步骤 3：运行并观察数据流

```bash
python demo_pipeline.py
```

- `get_settings()` 加载 `.env`，打印 `settings.term_list_path` 观察路径是否正确。
- `TermInput` 检查输入合法性。
- `OpenAIProvider` 请求 LLM（若无真实 API Key，可替换为前面练习的 `FakeOpenAIProvider`）。
- `TermProcessor` 根据索引生成 `memo_id`（从 `M002701` 开始）、将英文标签映射成中文。
- `CSVTermRepository.write_output` 输出 CSV 行。

### 步骤 4：用费曼方法复述

试着向另一位初学者解释：
1. **配置层** 如何找到 `.env` 并生成目录？
2. **Provider 层** 为什么要把 LLM 响应限制成 JSON？
3. **服务层** 如何把 `TermInput`、`LLMResponse` 和批次信息整合？
4. 运行 CLI 与自写脚本的差异是什么？（提示：CLI 只是自动化了同样的调用流程。）

若能用自己的话讲清楚，就证明你真正掌握了整个调用链。如果卡住，再回到上文对应章节复习。

---

## 11. 下一步

- 阅读 `ARCHITECTURE.md` 深入理解设计决策。
- 尝试实现一个新的 Provider（例如自建的本地模型），只需遵循 `LLMProvider` 协议。
- 为 `TermProcessor` 编写单元测试，练习如何 Mock Provider 与仓储。

恭喜完成初级入门！继续实践，你就能自如地扩展 Memosyne，甚至将它作为模板搭建自己的 LLM 管道。
